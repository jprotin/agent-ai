# ğŸš€ Installation Rapide d'un ModÃ¨le

## Pourquoi pas de modÃ¨le ?

Le service `ollama-setup` devrait installer `codellama` automatiquement au premier dÃ©marrage, mais parfois :
- Il Ã©choue silencieusement
- La connexion internet est lente/coupÃ©e
- Ollama n'Ã©tait pas prÃªt Ã  temps

## âœ… Solution Rapide (5-10 minutes)

### Option 1 : Script Automatique (RECOMMANDÃ‰)

```bash
# Installer codellama (recommandÃ© pour le code)
./install-model.sh codellama

# Ou un autre modÃ¨le
./install-model.sh llama3
./install-model.sh deepseek-coder
./install-model.sh mistral
```

### Option 2 : Commande Directe

```bash
# Installer codellama
docker exec -it ai-agent-ollama ollama pull codellama

# Attendre 5-10 minutes...
# VÃ©rifier l'installation
docker exec ai-agent-ollama ollama list
```

### Option 3 : Via start.sh

```bash
./start.sh pull-model codellama
```

## ğŸ“Š ModÃ¨les RecommandÃ©s

| ModÃ¨le | Taille | SpÃ©cialitÃ© | RecommandÃ© pour |
|--------|--------|-----------|-----------------|
| **codellama** | ~4 GB | Code | GÃ©nÃ©ration de code (DEFAULT) |
| **deepseek-coder** | ~4 GB | Code | Excellent pour le code |
| **llama3** | ~5 GB | GÃ©nÃ©ral | Bon Ã©quilibre |
| **mistral** | ~4 GB | GÃ©nÃ©ral | Rapide et efficace |
| **qwen2.5-coder** | ~4 GB | Code | Nouveau, trÃ¨s bon |

## ğŸ” VÃ©rifier les ModÃ¨les InstallÃ©s

```bash
# Lister les modÃ¨les
docker exec ai-agent-ollama ollama list

# Devrait afficher quelque chose comme :
# NAME              ID              SIZE      MODIFIED
# codellama:latest  8fdf8f752f6e    3.8 GB    2 minutes ago
```

## ğŸ› VÃ©rifier Pourquoi ollama-setup a Ã‰chouÃ©

```bash
# Voir les logs du service setup
docker logs ai-agent-ollama-setup

# RedÃ©marrer le service setup manuellement
docker-compose -f docker-compose.nohealth.yml up ollama-setup

# Ou recrÃ©er le service
docker-compose -f docker-compose.nohealth.yml rm -f ollama-setup
docker-compose -f docker-compose.nohealth.yml up -d ollama-setup
docker logs -f ai-agent-ollama-setup
```

## âš¡ Installation Ultra-Rapide

```bash
# Tout en une seule ligne
docker exec ai-agent-ollama ollama pull codellama && \
docker exec ai-agent-ollama ollama list && \
echo "âœ“ ModÃ¨le installÃ© ! Rechargez http://localhost:3000"
```

## ğŸ¯ AprÃ¨s Installation

1. **VÃ©rifier** :
   ```bash
   docker exec ai-agent-ollama ollama list
   ```

2. **Tester l'API** :
   ```bash
   curl http://localhost:3000/api/chat?action=models
   ```

3. **Recharger l'application** :
   - Ouvrir http://localhost:3000
   - SÃ©lectionner le modÃ¨le dans le dropdown
   - Envoyer un message de test

## ğŸ“ Installer Plusieurs ModÃ¨les

```bash
# Installer plusieurs modÃ¨les pour avoir le choix
docker exec ai-agent-ollama ollama pull codellama
docker exec ai-agent-ollama ollama pull llama3
docker exec ai-agent-ollama ollama pull deepseek-coder

# VÃ©rifier
docker exec ai-agent-ollama ollama list
```

## ğŸ’¾ Espace Disque Requis

- **1 modÃ¨le** : ~5 GB
- **2-3 modÃ¨les** : ~15 GB
- **5+ modÃ¨les** : ~25 GB

VÃ©rifier l'espace disponible :
```bash
df -h
docker system df
```

## ğŸ—‘ï¸ Supprimer un ModÃ¨le

```bash
# Supprimer un modÃ¨le pour libÃ©rer de l'espace
docker exec ai-agent-ollama ollama rm nom-du-modele

# Exemple
docker exec ai-agent-ollama ollama rm llama3
```

## ğŸ”„ Mettre Ã  Jour un ModÃ¨le

```bash
# Les modÃ¨les sont rÃ©guliÃ¨rement mis Ã  jour
docker exec ai-agent-ollama ollama pull codellama
```

## ğŸ†˜ ProblÃ¨mes Courants

### "pull model manifest: Get ... connection refused"

**Cause** : ProblÃ¨me rÃ©seau ou Ollama pas complÃ¨tement dÃ©marrÃ©

**Solution** :
```bash
# Attendre un peu
sleep 30

# RÃ©essayer
docker exec ai-agent-ollama ollama pull codellama
```

### "Error: model requires more system memory"

**Cause** : Pas assez de RAM

**Solution** :
- Utiliser un modÃ¨le plus petit (codellama:7b au lieu de codellama:34b)
- Augmenter la RAM allouÃ©e Ã  Docker (Settings > Resources)
- Fermer d'autres applications

### Le TÃ©lÃ©chargement est TrÃ¨s Lent

**Cause** : Connexion internet lente

**Solution** :
- Soyez patient (5-10 minutes normalement)
- Utiliser une meilleure connexion
- Le tÃ©lÃ©chargement peut Ãªtre repris s'il est interrompu

## âœ… Checklist Post-Installation

- [ ] `docker exec ai-agent-ollama ollama list` montre au moins 1 modÃ¨le
- [ ] `curl http://localhost:3000/api/chat?action=models` retourne des modÃ¨les
- [ ] Le dropdown de sÃ©lection de modÃ¨le dans l'app n'est pas vide
- [ ] Un message de test dans le chat reÃ§oit une rÃ©ponse

---

**TL;DR** :
```bash
./install-model.sh codellama
# Attendre 5-10 minutes
# Recharger http://localhost:3000
```

C'est tout ! ğŸ‰

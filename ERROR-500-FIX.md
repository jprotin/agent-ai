# ğŸ”§ Fix - Erreur 500 sur l'API Chat

## ğŸ”´ SymptÃ´me
```
Failed to load resource: the server responded with a status of 500 (Internal Server Error)
```

Dans le navigateur, l'erreur apparaÃ®t lors de l'envoi d'un message dans le chat.

## âœ… Diagnostic (2 minutes)

### Ã‰tape 1 : Lancer le Script de Diagnostic

```bash
chmod +x diagnose.sh
./diagnose.sh
```

Ce script va vÃ©rifier :
- Les conteneurs sont en cours d'exÃ©cution
- Ollama rÃ©pond sur le port 11434
- L'app peut contacter Ollama
- Les modÃ¨les sont installÃ©s
- L'API fonctionne

### Ã‰tape 2 : Voir les Logs de l'Application

```bash
# Logs en temps rÃ©el
docker logs -f ai-agent-app

# Ou via start.sh
./start.sh logs
```

Cherchez des messages comme :
- `Cannot connect to Ollama`
- `ECONNREFUSED`
- `fetch failed`
- `OllamaService`

## ğŸ¯ Solutions par Cause

### Cause 1 : Ollama n'est pas dÃ©marrÃ©

**SymptÃ´me dans les logs** :
```
[OllamaService] Connection error: fetch failed
```

**Solution** :
```bash
# VÃ©rifier l'Ã©tat
docker ps | grep ollama

# Si Ollama n'est pas running
./start.sh restart

# Attendre 30 secondes
sleep 30

# VÃ©rifier
curl http://localhost:11434/api/tags
```

### Cause 2 : Aucun ModÃ¨le InstallÃ©

**SymptÃ´me dans les logs** :
```
model 'codellama' not found
```

**Solution** :
```bash
# Lister les modÃ¨les
docker exec ai-agent-ollama ollama list

# Si vide, installer codellama
docker exec ai-agent-ollama ollama pull codellama

# Attendre 5-10 minutes
# VÃ©rifier
docker exec ai-agent-ollama ollama list
```

### Cause 3 : ProblÃ¨me de RÃ©seau Docker

**SymptÃ´me dans les logs** :
```
[OllamaService] Base URL: http://ollama:11434
Connection check result: FAILED
```

**Solution A** : VÃ©rifier la connectivitÃ© rÃ©seau
```bash
# Depuis le conteneur app, tester Ollama
docker exec ai-agent-app wget -O- http://ollama:11434/api/tags

# Si Ã§a Ã©choue, tester avec localhost
docker exec ai-agent-app wget -O- http://localhost:11434/api/tags
```

**Solution B** : RecrÃ©er le rÃ©seau
```bash
# ArrÃªter tout
./start.sh stop

# Supprimer le rÃ©seau
docker network rm ai-agent-network

# RedÃ©marrer
./start.sh
```

### Cause 4 : Variable d'Environnement Incorrecte

**SymptÃ´me dans les logs** :
```
[OllamaService] Base URL: http://localhost:11434
OLLAMA_BASE_URL env: undefined
```

**Solution** : VÃ©rifier la configuration
```bash
# VÃ©rifier les variables d'environnement de l'app
docker exec ai-agent-app env | grep OLLAMA

# Devrait afficher :
# OLLAMA_BASE_URL=http://ollama:11434

# Si absent, Ã©diter docker-compose.nohealth.yml
# et vÃ©rifier la section environment de app:
#   environment:
#     - OLLAMA_BASE_URL=http://ollama:11434
```

Puis redÃ©marrer :
```bash
./start.sh restart
```

### Cause 5 : Port 11434 BloquÃ©

**SymptÃ´me** :
```bash
curl http://localhost:11434/api/tags
# curl: (7) Failed to connect to localhost port 11434: Connection refused
```

**Solution** :
```bash
# VÃ©rifier que rien d'autre n'utilise le port
lsof -i :11434
netstat -an | grep 11434

# Voir les logs Ollama
docker logs ai-agent-ollama

# RedÃ©marrer Ollama
docker restart ai-agent-ollama
sleep 20
curl http://localhost:11434/api/tags
```

## ğŸ” Tests Manuels

### Test 1 : Ollama depuis l'HÃ´te

```bash
# Doit retourner la liste des modÃ¨les
curl http://localhost:11434/api/tags
```

### Test 2 : Ollama depuis le Conteneur App

```bash
# Doit aussi retourner la liste des modÃ¨les
docker exec ai-agent-app wget -O- http://ollama:11434/api/tags
```

### Test 3 : API Check

```bash
# Doit retourner {"connected":true}
curl http://localhost:3000/api/chat?action=check
```

### Test 4 : Envoi d'un Message de Test

```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Hello"}
    ],
    "model": "codellama"
  }'
```

Si Ã§a retourne une erreur, elle sera plus dÃ©taillÃ©e dans les logs.

## ğŸš€ ProcÃ©dure de RÃ©solution ComplÃ¨te

```bash
# 1. Diagnostic
./diagnose.sh

# 2. Voir les logs en temps rÃ©el (dans un autre terminal)
./start.sh logs

# 3. Selon le diagnostic, appliquer la solution correspondante

# 4. Si rien ne fonctionne, redÃ©marrage complet
./start.sh stop
docker network rm ai-agent-network 2>/dev/null
docker rm -f ai-agent-ollama ai-agent-app 2>/dev/null
./start.sh

# 5. Attendre le dÃ©marrage complet
sleep 60

# 6. VÃ©rifier Ã  nouveau
./diagnose.sh
```

## ğŸ“Š Checklist de VÃ©rification

- [ ] Les conteneurs `ai-agent-ollama` et `ai-agent-app` sont running
- [ ] `curl http://localhost:11434/api/tags` retourne du JSON
- [ ] Au moins un modÃ¨le est installÃ© (`docker exec ai-agent-ollama ollama list`)
- [ ] L'app peut contacter Ollama (`docker exec ai-agent-app wget -O- http://ollama:11434/api/tags`)
- [ ] L'API check retourne `{"connected":true}`
- [ ] Pas d'erreur dans les logs (`docker logs ai-agent-app`)

## ğŸ†˜ Si Rien ne Fonctionne

### Collecter les Informations

```bash
# CrÃ©er un fichier de debug
echo "=== Conteneurs ===" > debug-500.txt
docker ps -a >> debug-500.txt

echo -e "\n=== Logs Ollama ===" >> debug-500.txt
docker logs ai-agent-ollama --tail 50 >> debug-500.txt

echo -e "\n=== Logs App ===" >> debug-500.txt
docker logs ai-agent-app --tail 50 >> debug-500.txt

echo -e "\n=== Test Ollama ===" >> debug-500.txt
curl http://localhost:11434/api/tags >> debug-500.txt 2>&1

echo -e "\n=== Test API ===" >> debug-500.txt
curl http://localhost:3000/api/chat?action=check >> debug-500.txt 2>&1

echo -e "\n=== Variables Env ===" >> debug-500.txt
docker exec ai-agent-app env | grep OLLAMA >> debug-500.txt

cat debug-500.txt
```

### Solution de Dernier Recours

```bash
# Nettoyage TOTAL (supprime aussi les modÃ¨les)
docker-compose -f docker-compose.nohealth.yml down -v
docker system prune -a -f

# RedÃ©marrage propre
./start.sh

# Les modÃ¨les devront Ãªtre retÃ©lÃ©chargÃ©s (~5-10 minutes)
```

## ğŸ’¡ PrÃ©vention

Pour Ã©viter ce problÃ¨me :

1. **Toujours arrÃªter proprement** :
   ```bash
   ./start.sh stop
   ```

2. **Attendre le dÃ©marrage complet** :
   AprÃ¨s `./start.sh`, attendez 1-2 minutes avant d'utiliser l'app

3. **VÃ©rifier rÃ©guliÃ¨rement** :
   ```bash
   ./diagnose.sh
   ```

## ğŸ“š Documentation AssociÃ©e

- **diagnose.sh** - Script de diagnostic automatique
- **TROUBLESHOOTING.md** - Guide gÃ©nÃ©ral de dÃ©pannage
- **DOCKER.md** - Configuration Docker

---

**TL;DR** :
```bash
./diagnose.sh          # Diagnostic
./start.sh logs        # Voir les logs
./start.sh restart     # RedÃ©marrer si nÃ©cessaire
```
